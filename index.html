<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Hamidreza Kasaei</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="icon" href="images/avatar.ico">
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

	<!-- Header -->
	<section id="header">
		<header href="#news">
			<span class="image avatar"><img src="images/hamid_new_photo.jpg" alt="" /></span>
			<h1 id="logo"><a href="#">Hamidreza Kasaei</a></h1>
			<a href="#about" >Assistant Professor,<br />
				Department of Artificial Intelligence,<br />
				University of Groningen,  Netherlands.	</a>
		</header>
		<nav id="nav">
			<ul>
				<!-- <li><a href="#about" class="active">About Me</a></li> -->
				<li><a href="#news">Latest News</a></li>
				<li><a href="#research">Research & Publication</a></li>
				<li><a href="https://www.ai.rug.nl/irl-lab" target="_blank">IRL-Lab</a></li>
				<li><a href="https://www.ai.rug.nl/irl-lab/index.html#people" target="_blank">Students  </a></li>

				<!-- <li><a href="#students">Students </a></li> -->
				<li><a href="#positions">Open Positions </a></li>				
				<!-- <li><a href="https://www.ai.rug.nl/irl-lab/index.html#join_us" target="_blank">Open Positions </a></li>				 -->
				<li><a href="#teaching">Teaching & Contact</a></li>

			</ul>
		</nav>
		<footer>
			<ul class="icons">
				<li><a target="_blank" href="https://twitter.com/HamidrezaKasaei" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
				<li><a target="_blank" href="https://scholar.google.com/citations?user=VFr_XuYAAAAJ&hl=en" class="icon fa-book"><span class="label">Google Scholar</span></a></li>
				<li><a target="_blank" href="https://www.linkedin.com/in/hamidreza-kasaei-49b83b57/" class="icon fa-linkedin"><span class="label">linkedin</span></a></li>
				<li><a target="_blank" href="https://github.com/SeyedHamidreza/" class="icon fa-github"><span class="label">Github</span></a></li>
				<li><a target="_blank" href="mailto:hamidreza.kasaei@rug.nl" class="icon fa-envelope"><span class="label">Email</span></a></li>
			</ul>
		</footer>
	</section>

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Main -->
		<div id="main">

			<!-- One -->
			<section id="about">
				<div>
				</div>
				<!-- <div class="image main" data-position="center">
				<img src="images/banner.jpg" alt="" />
				</div>-->
				<div class="container">

				<header class="major">
					<h2 style="text-align: center;">Hamidreza Kasaei
					</h2>

				</header>
				
				<div class="features">
					<article>
					<span class="image"><img src="images/hamidreza.jpeg" alt=""> <p style="text-align: center;" class="icon fa-envelope">  hamidreza.kasaei@rug.nl</p></span>
					<div class="inner">
						<!-- <h2 style="text-align: center;">Hamidreza Kasaei</h2> -->
			
						<p style="text-align: justify; color: rgb(0, 0, 0);">
						I am an Assistant Professor in the Department of Artificial Intelligence at the <b> <a href="http://rug.nl/" target="_blank" style="color: rgb(0,0, 255);"> University of Groningen</a></b>, the Netherlands. 
						I have extensive background in computer vision, machine learning and robotics. 
						My main research interests lie in the area of <b  style="color: rgb(0, 0, 255);"> 
						3D Object Perception and Object Manipulation</b>. 
						<!-- Currently, I am developing an artificial cognitive system for robots to provide a tight coupling between perception and manipulation.  -->
						These days, I am particularly interested in enabling robots to incrementally learn from past experiences and intelligently and safely
						interact with non-expert human users using data-efficient open-ended machine-learning techniques. 
						Therefore, my research group focuses on <b> <a href="https://www.ai.rug.nl/irl-lab/" target="_blank" style="color: rgb(0,0, 255);">Lifelong Interactive Robot Learning (IRL-Lab)</a></b>, which we work at the cutting edge of robotics research.	
						<!-- For more information about our research, please visit the <b> <a href="https://www.ai.rug.nl/irl-lab/" target="_blank" style="color: rgb(0,0, 255);"> webpage of my research group</a></b>. -->
						


						<!-- This coupling is necessary for assistive robots, not only to perform manipulation tasks appropriately but also to robustly adapt to new environments by handling new objects.  -->
						</p>
					</div>
					</article>
				</div>
				
				<!-- <p style="text-align: justify; color: rgb(0, 0, 0);"> -->
					
					<!-- During my Ph.D., I got an opportunity to work on an FP7 Project named <b> 
					<a href="http://project-race.eu/" target="_blank" style="color: rgb(0,0, 255);"> RACE: Robustness by Autonomous Competence Enhancement</a></b>. 
					In this project, I was mainly responsible to develop interactive open-ended learning approaches to recognize multiple objects and their grasp affordances 
					concurrently.  During my master, I studied face recognition using single normal reference image and statistical features. Besides, I worked on middle size 
					soccer robot and humanoid robot and obtained different ranks in RoboCup competitions.  -->

						<!-- As researcher in Robotics, I envision a world where robots can easily assist, help, and empower people in a large diversity of scenarios and tasks. 
						To make this dream come true, I spend my days working on tools that allow robots to interact with humans smartly, naturally and safely. In this context, my research lies in the intersection of machine learning, robot control and human-robot interaction. -->

						<!-- Navigate my web page if you want to know more about me and my work. Enjoy! -->
				<!-- </p> -->
							
				<p style="text-align: justify; color: rgb(0, 0, 0);"></p>
				<div style="text-align: center; color: rgb(20, 0, 0);"> 
					/
					<a target="_blank" href="https://www.ai.rug.nl/irl-lab"> IRL-Lab</a> /
					<!-- <a target="_blank" href="documents/Hamidreza_Kasaei_PhD_thesis.pdf"> Bio</a> / -->
					<!-- <a target="_blank" href="documents/Hamidreza_Kasaei_PhD_thesis.pdf"> PhD Thesis</a> / -->
					<a href="https://www.ai.rug.nl/irl-lab/publications.html">Publications</a> /
					<a target="_blank" href="https://scholar.google.com/citations?user=VFr_XuYAAAAJ&hl=en">Google Scholar</a> /
					<a target="_blank" href="https://www.researchgate.net/profile/Hamidreza_Kasaei?ev=hdr_xprf" target="_blank">ResearchGate </a> /
					<a target="_blank" href="https://www.linkedin.com/in/hamidreza-kasaei-49b83b57/">LinkedIn </a> / 
					<a target="_blank" href="https://github.com/SeyedHamidreza/">Github </a> / 
					<a target="_blank" href="https://www.youtube.com/channel/UCEPBEyQfiv1P8wfuYjuWy4Q">YouTube </a> / 
					<!-- <a target="_blank" href="mailto:hamidreza.kasaei@rug.nl">Email</a> /  -->
				</div>
			</p>
	</div>
</section>




<section id="news">
	<div class="container">
		<h3 style="color: rgb(0, 0, 0);" >Recent Work</h3>
		<table style="text-align: center;">
			
			<tr >
				<td><a tyle="text-align:center" href="https://youtu.be/VmIFF__c_84" target="_blank"  class="image"><img src="videos/throwing_objects.gif" alt="" width="400" height= "250"/></a> </td>
				<td><a href="https://youtu.be/c-4lzjbF7fY" target="_blank"  class="image"><img src="videos/dual_arm_grasping.gif" alt="" width="400" height= "250"/></a> </td>
				<!-- <td><a class="image"><img src="videos/neural_motion_planning.gif" alt="" width="350" /></a> </td> -->
			</tr>
			<tr>
				<td><b style="text-align:center; color: rgb(0, 150, 25);"> <a target="_blank" href="https://arxiv.org/pdf/2210.00609.pdf">Throwing Object into a Moving Basket </b> </a></td>
				<td><b style="text-align:center; color: rgb(0, 150, 25);"> <a target="_blank" href="https://linkinghub.elsevier.com/retrieve/pii/S0921889022002020">Multi-View Object Grasping in Dense Clutter</b> </a></td>
				
			</tr>
			</p>
		</table>
	</div>
</section>

<!-- Two -->
<section id="news">
	<div class="container">
		<h3 style="color: rgb(0, 0, 0);" >Latest News</h3>

		<p style="text-align: justify; color: rgb(0, 0, 0);">

		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> June. 2023:</b>  I have been selected as an <b> <a href="https://www.ieee-ras.org/publications/ra-l" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> Outstanding Associate Editor for the IEEE Robotics and Automation Letters!</a> </b> 									
		</td></tr>
		<br/>

		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> April. 2023:</b> Our paper titled <b> <a href="https://arxiv.org/pdf/2103.09863.pdf" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> MORE: Simultaneous Multi-View 3D Object Recognition and Pose Estimation </b></a> got accepted to <b><a href="https://www.sciencedirect.com/journal/robotics-and-autonomous-systems" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> Intelligent Service Robotics! - [open-access]</b></a>!
		</td></tr>
		<br/>
		
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> March. 2023:</b> 
			We will organize a full-day workshop on the topic of <b><a href="https://ai-workshops.github.io/interdisciplinary-exploration-of-gmpl/index.html" target="_blank" class="external text" rel="nofollow" style="color: rgb(0,0, 255);"> "Interdisciplinary Exploration of Generalizable Manipulation Policy Learning: Paradigms and Debates"</a> </b> at <b><a href="https://roboticsconference.org/" 
				class="external text" title="https://roboticsconference.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">RSS 2023</a></b>. 		
		<br/>
	
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Feb. 2023:</b> Zhenxing Zhang successfully defended his Ph.D. thesis <b><a href="https://www.rug.nl/about-ug/latest-news/events/promoties/?hfId=123070" class="external text" title="" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">
			Generative Adversarial Networks for	Diverse and Explainable	Text-to-Image Generation. </a> </b> Congratulation Zhenxing!
					
		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Jan. 2023:</b> Hamed Ayoobi successfully defended his Ph.D. thesis <b><a href="https://www.rug.nl/fse/phd-ceremonies/?hfId=121335" class="external text" title="" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">
		Explain What You See: Argumentation-Based Learning and Robotic Vision. </a> </b> Congratulation Hamed!
		<br/>

		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Jan. 2023:</b> Hamidreza Kasaei is serving as  <b>associate editor </b>for the <b><a 
			href="https://ieee-iros.org/" class="external text" title="https://ieee-iros.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">IROS 2023!
		</a></b>
		<br/>

		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Jan. 2023:</b> Four of our papers have been accepted at <b><a 
			href="http://www.icra2023.org/" class="external text" title="http://www.icra2023.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">ICRA'23, the premier conference in robotics. 
		</a> </b> A big thank you to my students and collaborators!
		<br/> <a style="color: rgb(0, 150, 25);" href="https://arxiv.org/pdf/2210.00609.pdf" target="_blank">1- Throwing Objects into A Moving Basket While Avoiding Obstacles. </a> <a style="color: rgb(216, 35, 11);" href="https://youtu.be/VmIFF__c_84" target="_blank">[video]</a>
		<br/> <a style="color: rgb(0, 150, 25);" href="https://arxiv.org/pdf/2301.07037.pdf" target="_blank">2- Explain What You See: Open-Ended Segmentation and Recognition of Occluded 3D Objects. </a> <a style="color: rgb(216, 35, 11);" href="https://youtu.be/42Iq2evlajU" target="_blank">[video]</a>
		<br/> <a style="color: rgb(0, 150, 25);" href="https://arxiv.org/pdf/2302.07824.pdf" target="_blank">3- Instance-wise Grasp Synthesis for Robotic Grasping. </a> <a style="color: rgb(216, 35, 11);" href="https://youtu.be/riBXMgrupUw" target="_blank">[video]</a>
		<br/> <a style="color: rgb(0, 150, 25);" >4- Frontier Semantic Exploration for Visual Target Navigation </a> <a style="color: rgb(216, 35, 11);" href="https://youtu.be/NpP0jRdFZoo" target="_blank">[video]</a>
		

		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Nov. 2022:</b> Hamidreza Kasaei gave an invited talk at the 
				<a href="https://umcgresearch.org/w/ai-and-robotics-in-healthcare-dashevent" class="external text" title="" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);" > AI & Robotics in Healthcare | Data Science Center in Health (DASH) </a> on <b>
				<a href="https://youtu.be/rVwofJ_hhsQ?t=1669" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);"> Towards Lifelong Assistive Robotics: How to make life easier for people with disabilities? </a></b>
				<a href="https://youtu.be/rVwofJ_hhsQ?t=1669" class="external text" title="" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);" > [video]</a> <b>				
		</b>
		

		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Nov. 2022:</b> Hamidreza Kasaei gave an invited talk at the  
			<a href="https://www.ua.pt/" class="external text" title="" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);" > University of Aveiro, Portugal | Seminar in Robotics and Intelligent Systems </a> on <b>
			<a rel="nofollow" style="color: rgb(0,0, 255);"> Robotics for Society: How robots can help us with a wide variety of tasks in different domains incrementally? </a>
		</b>
			
			
		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Oct. 2022:</b> Our paper titled <b> <a href="https://linkinghub.elsevier.com/retrieve/pii/S0921889022002020" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> MVGrasp: Real-Time Multi-View 3D Object Grasping in Highly
			Cluttered Environments </b></a> got accepted to <b><a href="https://www.sciencedirect.com/journal/robotics-and-autonomous-systems" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> Robotics and Autonomous Systems (RAS)! - [open-access]</b></a>!
		</b>

		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Sep. 2022:</b> Hamidreza Kasaei is serving as  <b>associate editor </b>for the <b><a 
			href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369" class="external text" title="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">IEEE Robotics and Automation Letters (RA-L)!
		</a></b>
		
		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> March. 2022:</b> Our paper titled <b> <a href="https://arxiv.org/pdf/2205.12089.pdf" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> Sim-to-Real Transfer of Visual Grounding for Human-Aided Ambiguity Resolution </b></a> got accepted to <b><a
			href="https://lifelong-ml.cc/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> Conference on Lifelong Learning Agents (CoLLAs 2022)!</b></a> Congrats Georgios! 						
		</b>

		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Sep. 2022:</b> Hamidreza Kasaei is serving as  <b>associate editor </b>for the <b><a 
			href="http://www.icra2023.org/" class="external text" title="http://www.icra2023.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">IEEE ICRA 2023!
		</a></b>

		<br/>
		<b class="icon fa-flag" style="color: rgb(0, 150, 25);"> June 2022:</b> We will organize a full-day workshop on <b><a href="http://www.robot-learning.ml/2022/" target="_blank" class="external text" rel="nofollow" style="color: rgb(0,0, 255);"> 
			5th Robot Learning Workshop: Trustworthy Robotics</a> </b> at <b><a href="https://nips.cc/" class="external text" title="https://nips.cc/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">NeruIPS2022</a></b>. </td></tr>


		<br /><b class="icon fa-flag" style="color: rgb(0, 150, 25);"> March. 2022:</b> Our paper titled <b> Lifelong 3D Object Recognition and Grasp Synthesis using Dual Memory Recurrent Self-Organization Networks</b> got accepted to <b><a 
			href="https://www.journals.elsevier.com/neural-networks" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">  Neural Networks Journal! </b></a> Congrats Krishna!
		</b>

		<br /><b class="icon fa-flag" style="color: rgb(0, 150, 25);"> Jan. 2022:</b>  Hamidreza Kasaei is serving as  <b>associate editor </b>for the <b><a 
			href="http://www.iros2022.org/" class="external text" title="http://www.iros2022.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> IEEE/RSJ IROS 2022!</a>
		</b>


			<!-- <br /><b style="color: rgb(0, 150, 25);">* Oct. 2021:</b> Our paper titled <b> Local-HDP: Interactive open-ended 3D object category recognition in real-time robotic scenarios</b> got accepted to <b><a 
				href="https://www.sciencedirect.com/science/article/pii/S0921889021001962" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">  Robotics and Autonomous Systems (RAS)! </b></a> Congrats Hamed!
			</b> -->

			<!-- <br /><b style="color: rgb(0, 150, 25);">* Sep. 2021:</b> Hamidreza Kasaei is serving as  <b>associate editor </b>for the <b><a
				href="http://www.icra2021.org/" class="external text" title="http://www.icra2022.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">IEEE/RSJ ICRA 2022!
			</a></b>

			<br /><b style="color: rgb(0, 150, 25);">* July 2021:</b> We will organize a full-day workshop on <b><a href="http://www.robot-learning.ml/2021/" target="_blank" class="external text" rel="nofollow" style="color: rgb(0,0, 255);"> 4th Robot Learning Workshop: Self-Supervised and Lifelong Learning</a> </b> at <b><a href="https://nips.cc/" class="external text" title="https://nips.cc/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">NeruIPS2021</a></b>. </td></tr>

			<br /><b style="color: rgb(0, 150, 25);">* July. 2021:</b> Our paper titled <b> The State of Lifelong Learning in Service Robots: Current Bottlenecks in Object Perception and Manipulation</b> got accepted to <b><a 
				href="https://www.springer.com/journal/10846" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">  Journal of Intelligent & Robotic Systems </b></a>									
			</b>

			<br /><b style="color: rgb(0, 150, 25);">* May. 2021:</b> I gave an invited talk on <b><a rel="nofollow" style="color: rgb(0,0, 255);"> Lifelong Robot Learning in Human-centric Environments: From Object Perception to Object Manipulation</a></b> at the <a href="https://www.lincoln.edu/" class="external text" title="https://www.lincoln.edu/" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);" > University of Lincoln, UK </a>

			<br /><b style="color: rgb(0, 150, 25);">* May. 2021:</b> Our paper titled <b>Open-Ended Fine-Grained 3D Object Categorization by Combining Shape and Texture Features in Multiple Colorspaces</b> got accepted to <b><a 
				href="https://humanoids-2020.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">  IEEE-RAS International Conference on Humanoid Robots (Humanoids2020)! </b></a> Congrats Nils!
			</b>

			<br /><b style="color: rgb(0, 150, 25);">* April. 2021:</b> Our paper titled <b>3D_DEN: Open-ended 3D Object Recognition Using Dynamically Expandable Networks</b> got accepted to <b><a 
				href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7274989" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);"> IEEE Transactions on Cognitive and Developmental Systems! </b></a> Congrats Sudhakaran!
			</b>
			<br /><b style="color: rgb(0, 150, 25);">* March. 2021:</b> Our paper titled <b>Self-Imitation Learning by Planning</b> got accepted to <b><a 
				href="http://www.icra2021.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">ICRA2021! </b></a> Congrats Sha!
			</b>
			<br /><b style="color: rgb(0, 150, 25);">* Feb. 2021:</b> I am serving as  <b>associate editor </b>for the <b><a 
				href="https://www.iros2021.org/" class="external text" title="https://www.iros2021.org/" target="_blank"  rel="nofollow" style="color: rgb(0,0, 255);">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)
			</a></b>

			<br /><b style="color: rgb(0, 150, 25);">* Feb. 2021:</b> I gave an invited talk at the <a href="https://www.bosch-ai.com/" class="external text" title="https://www.bosch-ai.com/" target="_blank" rel="nofollow" style="color: rgb(0,0, 255);" > Bosch Center for Artificial Intelligence (BCAI) </a> on <b><a rel="nofollow" style="color: rgb(0,0, 255);"> Robots Beyond the Factory: Open-ended Robot Learning in Human-Centric Environments!</a></b> -->

		</p>

</section>


<!-- Three -->
<section id="research">
	<div class="container">
		<h3 style="color: rgb(0, 0, 0);">Research & Publication</h3>
		<p style="text-align: justify; color: rgb(0, 0, 0);">
			My research interests focus on the intersection of <b style="color: rgb(0, 0, 0);"> robotics</b>, <b style="color: rgb(0, 0, 0);">machine learning</b> 
			and <b style="color: rgb(0, 0, 0);">machine vision</b>. 		
			I am interested in developing algorithms for intelligent robotic systems based on lifelong/continual learning and active exploration to enable robots to help humans in various daily tasks.
			<!-- I am interested in developing algorithms for intelligent robotic systems based on lifelong/continual learning and interactive 
			environment exploration to capable robots to demonstrate strong performance in helping humans in household and care-taking tasks, manufacturing and logistics, transportation and monitoring, and many other unstructured and human-centric environments. -->
			I have been investigating  on <b style="color: rgb(0, 0, 0);">  active perception and manipulation</b>, where robots use their mobility and manipulation capabilities to model the world better. I have evaluated my works on different platforms including PR2, robotic arms, and humanoid robots. 
			Please navigate <b style="color: rgb(0, 0, 255);"><i><a href="https://www.ai.rug.nl/irl-lab/publications" target="_blank" >the publications pages of my research group (IRL-Lab)</a></i></b>, if you are intersted to know more our research.		
			<!-- My up-to-date list of publications can be found on my <b> <a  href="https://scholar.google.com/citations?user=VFr_XuYAAAAJ&hl=en" target="_blank" style="color: rgb(0, 0, 255);">  Google scholar account </a></b>. -->

			</p>

			<p style="text-align: justify; color: rgb(0, 0, 0);">
				My research group (<b style="color: rgb(0, 0, 255);"><a href="https://www.ai.rug.nl/irl-lab/">IRL-Lab</a></b>), mainly focuses on interactive robot learning to 
				make robots capable of learning in an open-ended fashion by interacting with non-expert human users. 
				More specifically, we have been developing this goal over <b style="color: rgb(0, 0, 0);">six particular research directions</b>:  
			</p>

			  

<!-- ***************************************************** -->
<!-- ***************************************************** -->
<!-- ***************************************************** -->
<div class="features">
	 
	<article>
		<!-- serve_a_coke.gif / good.gif -->
		<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image" ><img src="videos/serve_a_coke.gif" alt="" width="100%"/></a>
		<div class="inner">
			<h4 style="text-align: justify; color: rgb(0, 0, 250);" >1 - Perception and Perceptual Learning</h4>
			<p style="text-align: justify; color: rgb(0, 0, 0);">
				We are interested in attaining a 3D understanding of the world around us. In particular, 
				the perception system provides important information that the robot has to use for interacting with users and
				environments. 
			</p>
		</div>
	</article>
	<!-- ***************************************************** -->

	<article>
		<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image"><img src="videos/dual_arm_grasping.gif" alt="" /></a>
		<div class="inner">
			<h4 style="text-align: justify; color: rgb(0, 0, 250);" >2- Object Grasping and Object Manipulation</h4>

			<p style="text-align: justify; color: rgb(0, 0, 0);">
				A service robot must be able to interact with the environment as well as human users. 
				We are interested in fundamental research in object-agnostic grasping, affordance detection, task-informed grasping, and object manipulation.
			</p>
		</div>
	</article>
	<!-- ***************************************************** -->	
	
	<article>
			<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image"><img src="images/lifelong.png" alt="" /></a>
			<div class="inner">
				<h4 style="text-align: justify; color: rgb(0, 0, 250);" >3- Lifelong Interactive Robot Learning</h4>
			
				<p style="text-align: justify; color: rgb(0, 0, 0);">
					A service robot must be able to interact with the environment as well as human users. 
					We are interested in fundamental research in object-agnostic grasping, affordance detection, task-informed grasping, and object manipulation.
				</p>
			</div>
	</article>
	<!-- ***************************************************** -->	
	<article>
			<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image"><img src="videos/bartender_web.gif" alt="" /></a>
			<div class="inner">

				<h4 style="text-align: justify; color: rgb(0, 0, 250);" >4- Dual-Arm Manipulation</h4>
			
				<p style="text-align: justify; color: rgb(0, 0, 0);">
					A dual-arm robot has very good manipulability and maneuverability which is necessary
					to accomplish a set of everyday tasks (dishwashing, hammering).
					We are interested in efficient imitation learning, collabrative manipulation, and large object manipulation. 
				</p>
			</div>
	</article>
	<!-- ***************************************************** -->
	<article>
			<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image"><img src="videos/neural_motion_planning.gif" alt="" /></a>
			<div class="inner">
									
				<h4 style="text-align: justify; color: rgb(0, 0, 250);" >5- Dynamic Robot Motion Planning</h4>

				<p style="text-align: justify; color: rgb(0, 0, 0);">
					We are interested in attaining fully reactive manipulation functionalities in a closed-loop manner. 
					Reactive systems have to continuously check if they are at risk of colliding while planners should check every configuration that the robot may attempt to use.
				</p>
			</div>
	</article>
	<!-- ***************************************************** -->
	<article>
			<a href="https://www.ai.rug.nl/irl-lab/publications.html" target="_blank" class="image"><img src="videos/pr2.gif" alt="" /></a>
			<div class="inner">

				<h4 style="text-align: justify; color: rgb(0, 0, 250);" >6- Exploiting Multimodality</h4>

				<p style="text-align: justify; color: rgb(0, 0, 0);">
					A service robot may sense the world through different modalities that may provide visual, haptic or auditory cues about the environment.  
					In this vein, we are interested in exploiting multimodality for learning better representations to improve robot's performance.
				</p>
			</div>
	</article>
	<!-- ***************************************************** -->
	

</div>


</section>
<!-- ***************************************************** -->
<!-- ***************************************************** -->
<!-- ***************************************************** -->

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 4 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 4 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 4 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- <section id="students">
	<div class="container">	
	<h3 style="color: rgb(0, 0, 0);"> PhD Students</h3>
	

	<h4> </h3>
		<div class="col-4"><span class="image fit"><img src="" alt="" /></span></div>

		<div class="box alt">
			<div class="row gtr-50 gtr-uniform">
				<div class="col-5"><span class="image fit"><img src="images/sha.png" alt="" /></span></div>
				<div class="col-7"><span class="image fit">
					<ul>
						<li style="text-align: justify; color: rgb(0, 0, 0);">Sha Luo (Oct.2018 ~ )</li>
						<li style="text-align: justify;">Deep Reinforcement Learning for Flexible Visually Guided Grasping</li>					
						<li style="text-align: justify;"> Advisors: Hamidreza Kasaei, Lambert Schomaker</li>					
					</ul>
					</span>
				</div>
			<div class="col-4"><span class="image fit"><img src="" alt="" /></span></div>
		</div>

		<div class="box alt">
			<div class="row gtr-50 gtr-uniform">
				<div class="col-5"><span class="image fit"><img src="images/georgios_project.png" alt="" /></span></div>
				<div class="col-7"><span class="image fit">
					<ul>
						<li style="text-align: justify; color: rgb(0, 0, 0);">Georgios Tziafas (Oct.2021 ~ )</li>
						<li style="text-align: justify;">Lifelong Learning for Dual-arm Manipulation Tasks in Human-centric Environments</li>					
						<li style="text-align: justify;"> Advisors: Lambert Schomaker, Hamidreza Kasaei</li>					
					</ul>
					</span>
				</div>
			<div class="col-4"><span class="image fit"><img src="" alt="" /></span></div>
		</div>
		
		<div class="box alt">
			<div class="row gtr-50 gtr-uniform">
				<div class="col-5"><span class="image fit"><img src="images/songsong_project.png" alt="" /></span></div>
				<div class="col-7"><span class="image fit">
					<ul>
						<li style="text-align: justify; color: rgb(0, 0, 0);">Songsong Xiong (Nov.2021 ~ )</li>
						<li style="text-align: justify;">Lifelong 3D Object Perception and Manipulation in Cluttered Environments</li>					
						<li style="text-align: justify;"> Advisors: Lambert Schomaker, Hamidreza Kasaei</li>					
					</ul>
					</span>
				</div>
			<div class="col-4"><span class="image fit"><img src="" alt="" /></span></div>
		</div>

	</article>

	<a href="https://www.ai.rug.nl/irl-lab/index.html#people" style="text-align: justify; color: rgb(0, 0, 250);">
		Please check out the full list of my students and the details of their projects on the IRL-Lab webpage!</a> </b>
	<br><br>
</section> -->

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 6 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 6 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 6 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<section id="positions">
	<div class="container">
	<h3 style="color: rgb(0, 0, 0);"> Open Positions</h3>
	
	<article style="color: rgb(0, 0, 0);">
	
		We are actively looking for students to work on amazing robotic projects that involve:
		<br> <br>
		<p style="color: rgb(0, 0, 0); text-align: justify; ">
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Deep learning-based method for 3D object perception.</a> <br>
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Visual representation learning for physical interaction (grasping and manipulation).</a>  <br>
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Deep reinforcement and imitation learning-based methods for planning & control.</a> <br> 
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Dual-arm object manipulation.</a> <br> 
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Lifelong Robot learning.</a> <br> 
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Efficient Supervision for Robot Learning.</a>  <br>
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Learning from Demonstration.</a> <br> 
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Multi-Task multimodal learning.</a> <br> 
			<a class="icon fa-check-circle" style="color: rgb(0, 0, 255);"> Simulation to real-world transfer learning (Sim2Real).</a> <br> 

		</p>
	
	
		If you are interested in doing your PhD/Master/Bachelor thesis in one of the above areas, or working on a project with me, please send me an e-mail including:
			</p>
			
			<ul class="feature-icons" style="text-align: justify;">
				<li class="fa-book" style="color: rgb(0, 0, 255);">Short CV</li>
				<li class="fa-cubes" style="color: rgb(0, 0, 255);">Short motivation letter</li>
			</ul>
			
			
			<p style="text-align: justify; color: rgb(0, 0, 0);">
			The motivation letter should state (½ - 1 page):
			<ul class="feature-icons">
				<li class="fa-diamond" style="color: rgb(0, 0, 255);">Topics that you are interested in</li>
				<li class="fa-signal" style="color: rgb(0, 0, 255);">Type of project (theoretical/applied)</li>
				<li class="fa-calendar" style="color: rgb(0, 0, 255);">Intended starting date</li>
				<li class="fa-folder-open-o" style="color: rgb(0, 0, 255);">Your relevant experiences</li>
				<!-- <li class="fa-code" style="color: rgb(0, 0, 255);">Programming languages and related</li> -->
			</ul>
			</p>

			</br>
			<b><p style="text-align: justify; font-size:20pt; color: rgb(150, 0, 0);">Seld-funded (externally funded) PhD, Master and Visiting Scholar</p></b>
			<p style="text-align: justify; color: rgb(0, 0, 0);">Good self-funded PhD, Master, and intern will be considered on a case by case basis. 
				If you are interested in doing your PhD at Interactive Robot Learning Lab and you have funding from your Government (e.g., China Scholarship Council (CSC) scholarship), 
				we can consider your application. 
			</p>
		</article>
	</div>
</section>

<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 5 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 5 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->
<!-- ^^^^^^^^^^^^^^^^^^^^^^^^^^ Section 5 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ -->

<section id="teaching">
<div class="container">
<h3 style="color: rgb(0, 0, 0);">Teaching</h3>

<p style="text-align: justify; color: rgb(0, 0, 0);">
Academic year 2021/2022: <br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://rugcognitiverobotics.github.io/" target="_blank"> WMAI003-05: Cognitive Robotics (Coordinator)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/frw/vak/show?code=KIB.AS03" target="_blank"> KIB.AS03: Autonomous Systems (Coordinator)</a><br/>

	
<p style="text-align: justify; color: rgb(0, 0, 0);">
Academic year 2020/2021: <br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://rugcognitiverobotics.github.io/" target="_blank"> WMAI003-05: Cognitive Robotics (Coordinator)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/frw/vak/show?code=KIB.AS03" target="_blank"> KIB.AS03: Autonomous Systems (Lecturer)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/let/vak/show?code=KIM.ML09" target="_blank"> WMAI18002: Deep Learning (Lecturer)</a><br/>

<!-- <p style="text-align: justify; color: rgb(0, 0, 0);">
Academic year 2019/2020: <br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://rugcognitiverobotics.github.io/" target="_blank"> KIM.CROB04: Cognitive Robotics (Coordinator)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/frw/vak/show?code=KIB.AS03" target="_blank"> KIB.AS03: Autonomous Systems (Lecturer)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/let/vak/show?code=KIM.ML09" target="_blank"> KIM.ML09: Machine Learning (Assistant)</a><br/>

<p style="text-align: justify; color: rgb(0, 0, 0);">
Academic year 2018/2019: <br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/frw/vak/show?code=KIB.AS03" target="_blank"> KIB.AS03: Autonomous Systems (Lecturer)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/let/vak/show?code=KIM.ML09" target="_blank"> KIM.ML09: Machine Learning (Assistant)</a><br/>
<a class="icon fa-book" style="color: rgb(0, 0, 255);" href="https://www.rug.nl/ocasys/rug//vak/show?code=WMAI18002" target="_blank"> WMAI18002: Deep Learning (Assistant)</a><br/> -->


</p>
</div>
</section>


<section>
<div class="container">
<h3 style="color: rgb(0, 0, 0);">Contact</h3>

	<div class="row">
		<div class="col-6 col-12-small">
				<p style="text-align: justify; color: rgb(0, 0, 0);">
					<br/><br/>
					Dr. Hamidreza Kasaei<br/>
					Artificial Intelligence Department,<br/>
					<a style="color: rgb(0, 0, 0);" href="https://www.rug.nl/" target="_blank"> University of Groningen</a>, <br/>
					Bernoulliborg building,<br/>
					Nijenborgh 9 9747 AG Groningen, <br/>
					The Netherlands. <br/>
					Office: 340 <br/>
					Tel: +31-50-363-33926<br/>
					Email: hamidreza.kasaei@rug.nl<br/>																							
				</p>
			</div>
			<div class="col-4 col-8-small">
				<div >

					<!-- iframe plugin v.4.5 wordpress.org/plugins/iframe/ -->
					<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2387.742488603945!2d6.534234515834465!3d53.2403922799569!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x47c9cd1a4fa87a5d%3A0xdd27b1b9723bb97b!2sBernoulliborg%2C%209747%20AG%20Groningen!5e0!3m2!1sen!2snl!4v1618743298198!5m2!1sen!2snl" width="600" height="400" style="border:0;" allowfullscreen="" loading="lazy"></iframe>				
				</div>
			</div>
	</div>


</div>
</section>


<!-- Footer -->
<section id="footer">
	<div class="container">
		<ul class="copyright">
			<!-- <li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li> -->
		</ul>
	</div>
</section>

</div>

<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>
</html>
